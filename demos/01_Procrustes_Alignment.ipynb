{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Procrustes Alignment for Walking Data\n",
    "\n",
    "This notebook loads the Berlin tethered walking dataset, performs Procrustes alignment\n",
    "to a reference fly model pose, and exports scaled keypoint data ready for STAC registration.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load CSV dataset with walking bout keypoints\n",
    "2. Extract and transform keypoints to model reference frame\n",
    "3. Get reference pose from MuJoCo fly model\n",
    "4. Apply Procrustes alignment with scaling\n",
    "5. Apply ground contact alignment\n",
    "6. Export aligned keypoints to H5 for STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup (must be before JAX import)\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_triton_gemm_any=True\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Adjust GPU as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard library\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "\n",
    "# MuJoCo\n",
    "import mujoco\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# H5 file I/O\n",
    "import h5py\n",
    "\n",
    "# JAX cache setup\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATH CONFIGURATION ===\n",
    "# Base paths - adjust these to your environment\n",
    "BASE_PATH = Path(\"/home/talmolab/Desktop/SalkResearch\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "STAC_MJX_PATH = BASE_PATH / \"stac-mjx\"\n",
    "\n",
    "# Input data\n",
    "CSV_DATA_PATH = DATA_PATH / \"wt_berlin_tethered_dataset.csv\"\n",
    "\n",
    "# Reference model path\n",
    "MODEL_PATH = STAC_MJX_PATH / \"models\" / \"fruitfly\" / \"fruitfly_force.xml\"\n",
    "\n",
    "# Output path for aligned keypoints\n",
    "OUTPUT_PATH = DATA_PATH / \"aligned_walking_keypoints.h5\"\n",
    "\n",
    "# === ALIGNMENT PARAMETERS ===\n",
    "FLOOR_HEIGHT = -0.125  # Target floor Z height in model units\n",
    "GROUND_CONTACT_PERCENTILE = 5.0  # Percentile for ground contact detection\n",
    "END_EFFECTOR_INDICES = jnp.array([4, 9, 14, 19, 24, 29])  # Indices of leg tips (claws)\n",
    "\n",
    "print(f\"CSV data path: {CSV_DATA_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Walking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV dataset\n",
    "print(f\"Loading data from {CSV_DATA_PATH}...\")\n",
    "full_df = pd.read_csv(CSV_DATA_PATH)\n",
    "print(f\"Loaded dataframe with shape: {full_df.shape}\")\n",
    "print(f\"Columns: {len(full_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column mappings for keypoints\n",
    "# Data uses L1, R1, L2, R2, L3, R3 for legs and A, B, C, D, E for joints\n",
    "legs_data = [\"L1\", \"R1\", \"L2\", \"R2\", \"L3\", \"R3\"]\n",
    "joints_data = [\"A\", \"B\", \"C\", \"D\", \"E\"]  # coxa, femur, tibia, tarsus, claw\n",
    "coords_data = [\"_x\", \"_y\", \"_z\"]\n",
    "\n",
    "# Build column names for keypoint positions\n",
    "joint_pos_columns = [\n",
    "    leg + joint + coord\n",
    "    for leg in legs_data\n",
    "    for joint in joints_data\n",
    "    for coord in coords_data\n",
    "]\n",
    "\n",
    "print(f\"Number of keypoint columns: {len(joint_pos_columns)}\")\n",
    "print(f\"Expected: 6 legs x 5 joints x 3 coords = 90\")\n",
    "\n",
    "# Verify columns exist\n",
    "missing_cols = [col for col in joint_pos_columns if col not in full_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"WARNING: Missing columns: {missing_cols[:5]}...\")\n",
    "else:\n",
    "    print(\"All keypoint columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bout(bout_kp):\n",
    "    \"\"\"\n",
    "    Transform keypoints from data reference frame to model reference frame.\n",
    "\n",
    "    Args:\n",
    "        bout_kp: ndarray of shape (T, 30, 3) - keypoints for one bout\n",
    "\n",
    "    Returns:\n",
    "        Transformed keypoints in model frame (cm units)\n",
    "    \"\"\"\n",
    "    # Swap X and Y axes (rotate around Z)\n",
    "    bout_kp = bout_kp[:, :, [1, 0, 2]]\n",
    "    # Flip Y axis\n",
    "    bout_kp[:, :, 1] *= -1\n",
    "    # Convert mm to cm\n",
    "    bout_kp *= 0.1\n",
    "    return bout_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract walking bouts\n",
    "all_bout_nums = full_df[\"walking_bout_number\"].unique()\n",
    "# Skip bout 0 (usually non-walking frames)\n",
    "all_bout_nums = all_bout_nums[all_bout_nums > 0]\n",
    "all_bout_nums = sorted(all_bout_nums)\n",
    "\n",
    "print(f\"Found {len(all_bout_nums)} walking bouts\")\n",
    "\n",
    "# Create bout dictionary with keypoint data\n",
    "bout_dict = {}\n",
    "\n",
    "for n, bout_num in enumerate(tqdm(all_bout_nums, desc=\"Extracting bouts\")):\n",
    "    bout_df = full_df[full_df[\"walking_bout_number\"] == bout_num]\n",
    "\n",
    "    # Extract keypoint positions and reshape to (T, 30, 3)\n",
    "    kp_raw = bout_df[joint_pos_columns].values.reshape(-1, 30, 3)\n",
    "\n",
    "    # Transform to model reference frame\n",
    "    kp_transformed = transform_bout(kp_raw.copy())\n",
    "\n",
    "    bout_key = f\"walking_bout{n:04d}\"\n",
    "    bout_dict[bout_key] = {\n",
    "        \"orig_kp\": kp_transformed,\n",
    "        \"bout_number\": bout_num,\n",
    "        \"n_frames\": len(bout_df),\n",
    "    }\n",
    "\n",
    "print(f\"\\nProcessed {len(bout_dict)} bouts\")\n",
    "print(f\"Example bout shape: {bout_dict['walking_bout0000']['orig_kp'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Reference Pose from MuJoCo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fly model\n",
    "print(f\"Loading MuJoCo model from {MODEL_PATH}...\")\n",
    "spec = mujoco.MjSpec().from_file(str(MODEL_PATH))\n",
    "mj_model = spec.compile()\n",
    "\n",
    "# Get tracking site names and indices\n",
    "site_names = [site.name for site in spec.sites if \"tracking\" in site.name]\n",
    "site_idxs = jnp.array([site.id for site in spec.sites if \"tracking\" in site.name])\n",
    "\n",
    "print(f\"Found {len(site_names)} tracking sites\")\n",
    "print(f\"Site names: {site_names[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference pose from default model configuration\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "mujoco.mj_forward(mj_model, mj_data)\n",
    "\n",
    "# Extract tracking site positions as reference pose\n",
    "ref_pose = mj_data.site_xpos[site_idxs].copy()\n",
    "\n",
    "# Center at first joint (L1A - coxa of left front leg)\n",
    "print(f\"Centering reference pose at: {ref_pose[0]} ({site_names[0]})\")\n",
    "ref_pose = ref_pose - ref_pose[0]\n",
    "\n",
    "print(f\"Reference pose shape: {ref_pose.shape}\")\n",
    "print(\n",
    "    f\"Reference pose range: X=[{ref_pose[:, 0].min():.4f}, {ref_pose[:, 0].max():.4f}]\"\n",
    ")\n",
    "print(\n",
    "    f\"                      Y=[{ref_pose[:, 1].min():.4f}, {ref_pose[:, 1].max():.4f}]\"\n",
    ")\n",
    "print(\n",
    "    f\"                      Z=[{ref_pose[:, 2].min():.4f}, {ref_pose[:, 2].max():.4f}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Procrustes Alignment Functions\n",
    "\n",
    "These functions implement:\n",
    "1. **Procrustes alignment with scaling**: Rigid body transformation + uniform scaling to align keypoints to reference pose\n",
    "2. **Ground contact alignment**: Ensures end effectors (leg tips) touch the ground plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes_with_scaling(source, target):\n",
    "    \"\"\"\n",
    "    Compute optimal rotation, translation, and scale to align source to target.\n",
    "\n",
    "    Uses Procrustes analysis with uniform scaling.\n",
    "\n",
    "    Args:\n",
    "        source: (N, 3) source points\n",
    "        target: (N, 3) target points\n",
    "\n",
    "    Returns:\n",
    "        aligned: (N, 3) aligned source points\n",
    "        info: dict with transformation parameters\n",
    "    \"\"\"\n",
    "    # Center both point sets\n",
    "    source_centered = source - jnp.mean(source, axis=0)\n",
    "    target_centered = target - jnp.mean(target, axis=0)\n",
    "\n",
    "    # Compute optimal rotation using SVD\n",
    "    H = source_centered.T @ target_centered\n",
    "    U, S, Vt = jnp.linalg.svd(H)\n",
    "\n",
    "    # Handle reflection case\n",
    "    d = jnp.sign(jnp.linalg.det(Vt.T @ U.T))\n",
    "    D = jnp.diag(jnp.array([1.0, 1.0, d]))\n",
    "\n",
    "    R = Vt.T @ D @ U.T\n",
    "\n",
    "    # Compute optimal scale\n",
    "    source_rotated = source_centered @ R.T\n",
    "    scale = jnp.sum(target_centered * source_rotated) / jnp.sum(\n",
    "        source_rotated * source_rotated\n",
    "    )\n",
    "\n",
    "    # Apply transformation\n",
    "    aligned = scale * (source_centered @ R.T) + jnp.mean(target, axis=0)\n",
    "\n",
    "    # Compute alignment error\n",
    "    error = jnp.sqrt(jnp.mean(jnp.sum((aligned - target) ** 2, axis=1)))\n",
    "\n",
    "    info = {\n",
    "        \"rotation\": R,\n",
    "        \"scale\": scale,\n",
    "        \"source_centroid\": jnp.mean(source, axis=0),\n",
    "        \"target_centroid\": jnp.mean(target, axis=0),\n",
    "        \"error\": error,\n",
    "    }\n",
    "\n",
    "    return aligned, info\n",
    "\n",
    "\n",
    "def vectorized_procrustes_with_scaling_avg(kp_sequence, reference):\n",
    "    \"\"\"\n",
    "    Apply Procrustes alignment using clip average (JIT-compatible).\n",
    "    \"\"\"\n",
    "    # Use average pose for computing transformation\n",
    "    avg_pose = jnp.mean(kp_sequence, axis=0)\n",
    "    _, transform_info = procrustes_with_scaling(avg_pose, reference)\n",
    "\n",
    "    R = transform_info[\"rotation\"]\n",
    "    scale = transform_info[\"scale\"]\n",
    "    source_centroid = jnp.mean(kp_sequence, axis=(0, 1), keepdims=True)[0]\n",
    "    target_centroid = jnp.mean(reference, axis=0)\n",
    "\n",
    "    # Apply same transformation to all frames\n",
    "    centered = kp_sequence - source_centroid\n",
    "    aligned = scale * jnp.einsum(\"tni,ij->tnj\", centered, R) + target_centroid\n",
    "\n",
    "    # Compute mean error across all frames\n",
    "    errors = jnp.sqrt(jnp.mean(jnp.sum((aligned - reference) ** 2, axis=-1), axis=-1))\n",
    "    transform_info[\"mean_error\"] = jnp.mean(errors)\n",
    "\n",
    "    return aligned, transform_info\n",
    "\n",
    "\n",
    "# JIT compile the average-based alignment (this is the one we'll use)\n",
    "jit_vectorized_procrustes_avg = jax.jit(vectorized_procrustes_with_scaling_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ground_plane(points):\n",
    "    \"\"\"\n",
    "    Fit a plane to 3D points using least squares.\n",
    "\n",
    "    Args:\n",
    "        points: (N, 3) points to fit\n",
    "\n",
    "    Returns:\n",
    "        normal: (3,) unit normal vector\n",
    "        d: plane offset (plane equation: normal . x = d)\n",
    "    \"\"\"\n",
    "    centroid = jnp.mean(points, axis=0)\n",
    "    centered = points - centroid\n",
    "\n",
    "    # SVD to find normal (smallest singular vector)\n",
    "    _, _, Vt = jnp.linalg.svd(centered)\n",
    "    normal = Vt[-1]  # Last row of Vt is the normal\n",
    "\n",
    "    # Ensure normal points upward (positive Z)\n",
    "    normal = jnp.where(normal[2] < 0, -normal, normal)\n",
    "\n",
    "    d = jnp.dot(normal, centroid)\n",
    "\n",
    "    return normal, d\n",
    "\n",
    "\n",
    "def rotation_matrix_to_align_vectors(v_from, v_to):\n",
    "    \"\"\"\n",
    "    Compute rotation matrix to align v_from to v_to.\n",
    "    Uses Rodrigues' rotation formula.\n",
    "    \"\"\"\n",
    "    v_from = v_from / jnp.linalg.norm(v_from)\n",
    "    v_to = v_to / jnp.linalg.norm(v_to)\n",
    "\n",
    "    axis = jnp.cross(v_from, v_to)\n",
    "    axis_norm = jnp.linalg.norm(axis)\n",
    "\n",
    "    # Handle parallel vectors\n",
    "    cos_angle = jnp.dot(v_from, v_to)\n",
    "\n",
    "    def compute_rotation(args):\n",
    "        axis, axis_norm, cos_angle = args\n",
    "        axis = axis / axis_norm\n",
    "        angle = jnp.arccos(jnp.clip(cos_angle, -1.0, 1.0))\n",
    "\n",
    "        # Rodrigues' formula\n",
    "        K = jnp.array(\n",
    "            [[0, -axis[2], axis[1]], [axis[2], 0, -axis[0]], [-axis[1], axis[0], 0]]\n",
    "        )\n",
    "        R = jnp.eye(3) + jnp.sin(angle) * K + (1 - jnp.cos(angle)) * (K @ K)\n",
    "        return R\n",
    "\n",
    "    # If vectors are nearly parallel, return identity\n",
    "    R = jax.lax.cond(\n",
    "        axis_norm < 1e-6,\n",
    "        lambda args: jnp.eye(3),\n",
    "        compute_rotation,\n",
    "        operand=(axis, axis_norm, cos_angle),\n",
    "    )\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def align_to_ground_plane_with_contact(\n",
    "    kp_sequence, end_eff_indices, percentile, target_z\n",
    "):\n",
    "    \"\"\"\n",
    "    Align keypoints so end effectors contact a horizontal ground plane.\n",
    "\n",
    "    Steps:\n",
    "    1. Find ground contact points (lowest percentile of end effector Z positions)\n",
    "    2. Fit a plane to these points\n",
    "    3. Rotate to make plane horizontal\n",
    "    4. Translate to target Z height\n",
    "    5. Clip any points below floor\n",
    "\n",
    "    Args:\n",
    "        kp_sequence: (T, N, 3) keypoint sequence\n",
    "        end_eff_indices: indices of end effector keypoints\n",
    "        percentile: percentile for ground contact detection\n",
    "        target_z: target floor height\n",
    "\n",
    "    Returns:\n",
    "        aligned: (T, N, 3) aligned keypoints\n",
    "        info: dict with alignment info\n",
    "    \"\"\"\n",
    "    # Extract end effector positions\n",
    "    endeff_xpos = kp_sequence[:, end_eff_indices]\n",
    "\n",
    "    # Find Z threshold for each end effector\n",
    "    z_thresholds = jnp.percentile(endeff_xpos[..., 2], percentile, axis=0)\n",
    "\n",
    "    # Collect ground contact points\n",
    "    def get_contact_points(ee_idx):\n",
    "        z_vals = endeff_xpos[:, ee_idx, 2]\n",
    "        threshold = z_thresholds[ee_idx]\n",
    "        mask = z_vals <= threshold\n",
    "        # Get mean position of contact frames\n",
    "        contact_pos = jnp.where(mask[:, None], endeff_xpos[:, ee_idx], jnp.nan)\n",
    "        return jnp.nanmean(contact_pos, axis=0)\n",
    "\n",
    "    ground_points = vmap(get_contact_points)(jnp.arange(len(end_eff_indices)))\n",
    "\n",
    "    # Fit ground plane\n",
    "    normal, d = fit_ground_plane(ground_points)\n",
    "\n",
    "    # Rotation to align ground normal with Z-axis\n",
    "    z_axis = jnp.array([0.0, 0.0, 1.0])\n",
    "    R = rotation_matrix_to_align_vectors(normal, z_axis)\n",
    "\n",
    "    # Apply rotation\n",
    "    rotated = jnp.einsum(\"ij,tnj->tni\", R, kp_sequence)\n",
    "\n",
    "    # Compute translation to target floor height\n",
    "    rotated_endeff = rotated[:, end_eff_indices]\n",
    "    min_z = jnp.percentile(rotated_endeff[..., 2], percentile)\n",
    "    translation = jnp.array([0.0, 0.0, target_z - min_z])\n",
    "\n",
    "    # Apply translation\n",
    "    translated = rotated + translation\n",
    "\n",
    "    # Clip points below floor\n",
    "    clipped = translated.at[..., 2].set(jnp.maximum(translated[..., 2], target_z))\n",
    "\n",
    "    # Count statistics\n",
    "    n_clipped = jnp.sum(translated[..., 2] < target_z)\n",
    "    n_contacts = jnp.sum(jnp.abs(clipped[:, end_eff_indices, 2] - target_z) < 0.001)\n",
    "\n",
    "    info = {\n",
    "        \"rotation_matrix\": R,\n",
    "        \"translation\": translation,\n",
    "        \"ground_normal\": normal,\n",
    "        \"z_thresholds\": z_thresholds,\n",
    "        \"n_clipped\": n_clipped,\n",
    "        \"n_contacts\": n_contacts,\n",
    "        \"n_ground_points\": len(end_eff_indices),\n",
    "        \"contact_ratio\": n_contacts / (kp_sequence.shape[0] * len(end_eff_indices)),\n",
    "    }\n",
    "\n",
    "    return clipped, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_alignment_pipeline(\n",
    "    kp_sequence, reference, end_eff_indices, percentile=5.0, target_z=-0.125\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete alignment pipeline: Procrustes + ground contact alignment.\n",
    "\n",
    "    Args:\n",
    "        kp_sequence: (T, N, 3) raw keypoint sequence\n",
    "        reference: (N, 3) reference pose\n",
    "        end_eff_indices: indices of end effector keypoints\n",
    "        percentile: percentile for ground contact detection\n",
    "        target_z: target floor height\n",
    "\n",
    "    Returns:\n",
    "        aligned: (T, N, 3) fully aligned keypoints\n",
    "        info: dict with pipeline info\n",
    "    \"\"\"\n",
    "    # Step 1: Procrustes alignment (using clip average)\n",
    "    procrustes_aligned, procrustes_info = vectorized_procrustes_with_scaling_avg(\n",
    "        kp_sequence, reference\n",
    "    )\n",
    "\n",
    "    # Step 2: Ground contact alignment\n",
    "    ground_aligned, ground_info = align_to_ground_plane_with_contact(\n",
    "        procrustes_aligned, end_eff_indices, percentile, target_z\n",
    "    )\n",
    "\n",
    "    info = {\"procrustes\": procrustes_info, \"ground_contact\": ground_info}\n",
    "\n",
    "    return ground_aligned, info\n",
    "\n",
    "\n",
    "# Create JIT-compiled version\n",
    "jit_complete_alignment = jax.jit(complete_alignment_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Alignment (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alignment(original, aligned, reference, frame_idx=0, title=\"Alignment\"):\n",
    "    \"\"\"\n",
    "    Visualize original, aligned, and reference poses in 3D.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    orig_frame = original[frame_idx] if original.ndim == 3 else original\n",
    "    aligned_frame = aligned[frame_idx] if aligned.ndim == 3 else aligned\n",
    "\n",
    "    # Original\n",
    "    ax1 = fig.add_subplot(131, projection=\"3d\")\n",
    "    ax1.scatter(orig_frame[:, 0], orig_frame[:, 1], orig_frame[:, 2], c=\"blue\", s=20)\n",
    "    ax1.set_title(\"Original\")\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "    ax1.set_zlabel(\"Z\")\n",
    "\n",
    "    # Aligned\n",
    "    ax2 = fig.add_subplot(132, projection=\"3d\")\n",
    "    ax2.scatter(\n",
    "        aligned_frame[:, 0], aligned_frame[:, 1], aligned_frame[:, 2], c=\"green\", s=20\n",
    "    )\n",
    "    ax2.scatter(\n",
    "        reference[:, 0], reference[:, 1], reference[:, 2], c=\"red\", s=20, alpha=0.5\n",
    "    )\n",
    "    ax2.set_title(\"Aligned (green) vs Reference (red)\")\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    ax2.set_zlabel(\"Z\")\n",
    "\n",
    "    # Overlay\n",
    "    ax3 = fig.add_subplot(133, projection=\"3d\")\n",
    "    ax3.scatter(\n",
    "        aligned_frame[:, 0],\n",
    "        aligned_frame[:, 1],\n",
    "        aligned_frame[:, 2],\n",
    "        c=\"green\",\n",
    "        s=20,\n",
    "        label=\"Aligned\",\n",
    "    )\n",
    "    ax3.scatter(\n",
    "        reference[:, 0],\n",
    "        reference[:, 1],\n",
    "        reference[:, 2],\n",
    "        c=\"red\",\n",
    "        s=20,\n",
    "        alpha=0.5,\n",
    "        label=\"Reference\",\n",
    "    )\n",
    "    # Draw floor plane\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(aligned_frame[:, 0].min(), aligned_frame[:, 0].max(), 10),\n",
    "        np.linspace(aligned_frame[:, 1].min(), aligned_frame[:, 1].max(), 10),\n",
    "    )\n",
    "    ax3.plot_surface(xx, yy, np.full_like(xx, FLOOR_HEIGHT), alpha=0.2, color=\"gray\")\n",
    "    ax3.set_title(f\"{title} - Frame {frame_idx}\")\n",
    "    ax3.set_xlabel(\"X\")\n",
    "    ax3.set_ylabel(\"Y\")\n",
    "    ax3.set_zlabel(\"Z\")\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test alignment on a single clip\n",
    "test_clip_idx = 25\n",
    "test_clip_key = f\"walking_bout{test_clip_idx:04d}\"\n",
    "\n",
    "if test_clip_key in bout_dict:\n",
    "    kp_test = jnp.array(bout_dict[test_clip_key][\"orig_kp\"])\n",
    "    ref_pose_jax = jnp.array(ref_pose)\n",
    "\n",
    "    print(f\"Testing alignment on {test_clip_key}\")\n",
    "    print(f\"Input shape: {kp_test.shape}\")\n",
    "\n",
    "    # Apply full alignment pipeline\n",
    "    aligned_test, info = jit_complete_alignment(\n",
    "        kp_test,\n",
    "        ref_pose_jax,\n",
    "        END_EFFECTOR_INDICES,\n",
    "        percentile=GROUND_CONTACT_PERCENTILE,\n",
    "        target_z=FLOOR_HEIGHT,\n",
    "    )\n",
    "\n",
    "    print(f\"Procrustes mean error: {info['procrustes']['mean_error']:.6f}\")\n",
    "    print(f\"Ground contact ratio: {info['ground_contact']['contact_ratio']:.1%}\")\n",
    "\n",
    "    # Visualize\n",
    "    visualize_alignment(\n",
    "        kp_test, aligned_test, ref_pose_jax, frame_idx=0, title=test_clip_key\n",
    "    )\n",
    "else:\n",
    "    print(f\"Clip {test_clip_key} not found. Available clips: {len(bout_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process All Bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all bouts through the alignment pipeline\n",
    "ref_pose_jax = jnp.array(ref_pose)\n",
    "\n",
    "alignment_errors = []\n",
    "contact_ratios = []\n",
    "\n",
    "for clip_key in tqdm(bout_dict.keys(), desc=\"Aligning bouts\"):\n",
    "    kp_clip = jnp.array(bout_dict[clip_key][\"orig_kp\"])\n",
    "\n",
    "    # Apply full alignment pipeline\n",
    "    aligned_clip, pipeline_info = jit_complete_alignment(\n",
    "        kp_clip,\n",
    "        ref_pose_jax,\n",
    "        END_EFFECTOR_INDICES,\n",
    "        percentile=GROUND_CONTACT_PERCENTILE,\n",
    "        target_z=FLOOR_HEIGHT,\n",
    "    )\n",
    "\n",
    "    # Store aligned keypoints\n",
    "    bout_dict[clip_key][\"aligned_kp\"] = np.array(aligned_clip)\n",
    "\n",
    "    # Track statistics\n",
    "    alignment_errors.append(float(pipeline_info[\"procrustes\"][\"mean_error\"]))\n",
    "    contact_ratios.append(float(pipeline_info[\"ground_contact\"][\"contact_ratio\"]))\n",
    "\n",
    "print(f\"\\nAlignment complete!\")\n",
    "print(\n",
    "    f\"Mean alignment error: {np.mean(alignment_errors):.6f} +/- {np.std(alignment_errors):.6f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mean contact ratio: {np.mean(contact_ratios):.1%} +/- {np.std(contact_ratios):.1%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot alignment statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(alignment_errors, bins=30, edgecolor=\"black\")\n",
    "axes[0].set_xlabel(\"Procrustes Alignment Error\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Alignment Error Distribution\")\n",
    "axes[0].axvline(\n",
    "    np.mean(alignment_errors),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {np.mean(alignment_errors):.4f}\",\n",
    ")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(contact_ratios, bins=30, edgecolor=\"black\")\n",
    "axes[1].set_xlabel(\"Ground Contact Ratio\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_title(\"Ground Contact Ratio Distribution\")\n",
    "axes[1].axvline(\n",
    "    np.mean(contact_ratios),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {np.mean(contact_ratios):.1%}\",\n",
    ")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Aligned Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for export\n",
    "print(f\"Preparing data for export to {OUTPUT_PATH}...\")\n",
    "\n",
    "# Verify all clips have aligned keypoints\n",
    "for clip_key, clip_data in bout_dict.items():\n",
    "    if \"aligned_kp\" not in clip_data:\n",
    "        print(f\"WARNING: {clip_key} missing aligned_kp!\")\n",
    "    else:\n",
    "        orig_shape = clip_data[\"orig_kp\"].shape\n",
    "        aligned_shape = clip_data[\"aligned_kp\"].shape\n",
    "        if orig_shape != aligned_shape:\n",
    "            print(\n",
    "                f\"WARNING: {clip_key} shape mismatch: orig={orig_shape}, aligned={aligned_shape}\"\n",
    "            )\n",
    "\n",
    "print(f\"Total clips to export: {len(bout_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to H5 file\n",
    "print(f\"Saving aligned keypoints to {OUTPUT_PATH}...\")\n",
    "\n",
    "with h5py.File(OUTPUT_PATH, \"w\") as f:\n",
    "    # Save metadata\n",
    "    f.attrs[\"description\"] = (\n",
    "        \"Procrustes-aligned walking keypoints for STAC registration\"\n",
    "    )\n",
    "    f.attrs[\"n_clips\"] = len(bout_dict)\n",
    "    f.attrs[\"floor_height\"] = FLOOR_HEIGHT\n",
    "    f.attrs[\"ground_contact_percentile\"] = GROUND_CONTACT_PERCENTILE\n",
    "    f.attrs[\"source_csv\"] = str(CSV_DATA_PATH)\n",
    "    f.attrs[\"model_path\"] = str(MODEL_PATH)\n",
    "\n",
    "    # Save keypoint names\n",
    "    kp_names = [f\"{leg}{joint}\" for leg in legs_data for joint in joints_data]\n",
    "    f.create_dataset(\"kp_names\", data=np.array(kp_names, dtype=\"S\"))\n",
    "\n",
    "    # Save reference pose\n",
    "    f.create_dataset(\"reference_pose\", data=ref_pose, compression=\"gzip\")\n",
    "\n",
    "    # Save each clip\n",
    "    clips_group = f.create_group(\"clips\")\n",
    "    clip_lengths = []\n",
    "\n",
    "    for clip_key, clip_data in tqdm(bout_dict.items(), desc=\"Saving clips\"):\n",
    "        clip_grp = clips_group.create_group(clip_key)\n",
    "        clip_grp.create_dataset(\n",
    "            \"orig_kp\", data=clip_data[\"orig_kp\"], compression=\"gzip\"\n",
    "        )\n",
    "        clip_grp.create_dataset(\n",
    "            \"aligned_kp\", data=clip_data[\"aligned_kp\"], compression=\"gzip\"\n",
    "        )\n",
    "        clip_grp.attrs[\"bout_number\"] = clip_data[\"bout_number\"]\n",
    "        clip_grp.attrs[\"n_frames\"] = clip_data[\"n_frames\"]\n",
    "        clip_lengths.append(clip_data[\"n_frames\"])\n",
    "\n",
    "    # Save clip lengths\n",
    "    f.create_dataset(\"clip_lengths\", data=np.array(clip_lengths))\n",
    "\n",
    "print(f\"\\nSaved {len(bout_dict)} clips to {OUTPUT_PATH}\")\n",
    "print(f\"Total frames: {sum(clip_lengths)}\")\n",
    "print(f\"Clip length range: {min(clip_lengths)} - {max(clip_lengths)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the saved file\n",
    "print(\"\\nVerifying saved file...\")\n",
    "with h5py.File(OUTPUT_PATH, \"r\") as f:\n",
    "    print(f\"File attributes: {dict(f.attrs)}\")\n",
    "    print(f\"Datasets: {list(f.keys())}\")\n",
    "    print(f\"Number of clips: {len(f['clips'])}\")\n",
    "\n",
    "    # Check first clip\n",
    "    first_clip = list(f[\"clips\"].keys())[0]\n",
    "    print(f\"\\nFirst clip ({first_clip}):\")\n",
    "    print(f\"  orig_kp shape: {f['clips'][first_clip]['orig_kp'].shape}\")\n",
    "    print(f\"  aligned_kp shape: {f['clips'][first_clip]['aligned_kp'].shape}\")\n",
    "\n",
    "print(f\"\\nOutput file ready for STAC registration: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Loaded the Berlin tethered walking dataset CSV\n",
    "2. Extracted walking bouts and transformed keypoints to model reference frame\n",
    "3. Applied Procrustes alignment with scaling to match the reference fly pose\n",
    "4. Applied ground contact alignment to ensure leg tips touch the floor\n",
    "5. Exported aligned keypoints to H5 format for STAC registration\n",
    "\n",
    "**Next step:** Use `02_STAC_Registration.ipynb` to run STAC on the aligned keypoints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic-mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
