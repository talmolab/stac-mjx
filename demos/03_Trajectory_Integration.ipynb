{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Trajectory Integration for Walking Data\n",
    "\n",
    "This notebook integrates FicTrac wheel rotation/displacement data with STAC-registered\n",
    "joint angles to create complete walking trajectories with proper body position and orientation.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load STAC IK output from Notebook 2\n",
    "2. Load FicTrac trajectory data from original CSV\n",
    "3. Calculate yaw orientation from trajectory direction\n",
    "4. Apply position and orientation offsets to qpos\n",
    "5. Optionally interpolate to higher frequency\n",
    "6. Export final trajectory-integrated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup (must be before JAX import)\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_triton_gemm_any=True\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Adjust GPU as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talmolab/Desktop/SalkResearch/mimic-mjx/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard library\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from scipy import interpolate\n",
    "\n",
    "# MuJoCo\n",
    "import mujoco\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# H5 file I/O\n",
    "import h5py\n",
    "\n",
    "# JAX cache setup\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAC IK input: /home/talmolab/Desktop/SalkResearch/data/stac_ik_output.h5\n",
      "CSV data: /home/talmolab/Desktop/SalkResearch/data/wt_berlin_tethered_dataset.csv\n",
      "Output: /home/talmolab/Desktop/SalkResearch/data/walking_trajectory_integrated.h5\n"
     ]
    }
   ],
   "source": [
    "# === PATH CONFIGURATION ===\n",
    "BASE_PATH = Path(\"/home/talmolab/Desktop/SalkResearch\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "STAC_MJX_PATH = BASE_PATH / \"stac-mjx\"\n",
    "\n",
    "# Input: STAC IK output from Notebook 2\n",
    "STAC_IK_PATH = DATA_PATH / \"stac_ik_output.h5\"\n",
    "\n",
    "# Input: Original CSV for FicTrac data\n",
    "CSV_DATA_PATH = DATA_PATH / \"wt_berlin_tethered_dataset.csv\"\n",
    "\n",
    "# Input: Aligned keypoints (for clip mapping)\n",
    "ALIGNED_KP_PATH = DATA_PATH / \"aligned_walking_keypoints.h5\"\n",
    "\n",
    "# Model path (for wing joint indices)\n",
    "MODEL_PATH = STAC_MJX_PATH / \"models\" / \"fruitfly\" / \"fruitfly_force.xml\"\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = DATA_PATH / \"walking_trajectory_integrated.h5\"\n",
    "\n",
    "# === PROCESSING PARAMETERS ===\n",
    "SMOOTHING_WINDOW = 75  # Window size for yaw smoothing\n",
    "Z_OFFSET = 0.0195  # Height offset for z position\n",
    "SOURCE_HZ = 300  # Source data frequency\n",
    "TARGET_HZ = 500  # Target frequency for interpolation (None to skip)\n",
    "\n",
    "# Default wing position (folded wings)\n",
    "DEFAULT_WING_POS = jnp.array([1.5, 0.814, -0.821, 1.5, 0.814, -0.821])\n",
    "\n",
    "print(f\"STAC IK input: {STAC_IK_PATH}\")\n",
    "print(f\"CSV data: {CSV_DATA_PATH}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load STAC IK Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STAC IK output from /home/talmolab/Desktop/SalkResearch/data/stac_ik_output.h5...\n",
      "Attributes: {}\n",
      "qpos shape: (692333, 36)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'clip_lengths' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mqpos shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqpos_all.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load clip lengths\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m clip_lengths = \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclip_lengths\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[:]\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of clips: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(clip_lengths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Load other data if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SalkResearch/mimic-mjx/lib/python3.12/site-packages/h5py/_hl/group.py:357\u001b[39m, in \u001b[36mGroup.__getitem__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid HDF5 object reference\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     oid = \u001b[43mh5o\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAccessing a group is done with bytes or str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5o.pyx:257\u001b[39m, in \u001b[36mh5py.h5o.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: \"Unable to synchronously open object (object 'clip_lengths' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# Load STAC IK results from Notebook 2\n",
    "print(f\"Loading STAC IK output from {STAC_IK_PATH}...\")\n",
    "\n",
    "with h5py.File(STAC_IK_PATH, \"r\") as f:\n",
    "    print(f\"Attributes: {dict(f.attrs)}\")\n",
    "\n",
    "    # Load qpos (joint positions)\n",
    "    qpos_all = f[\"qpos\"][:]\n",
    "    print(f\"qpos shape: {qpos_all.shape}\")\n",
    "\n",
    "    # Load clip lengths\n",
    "    clip_lengths = f[\"clip_lengths\"][:]\n",
    "    print(f\"Number of clips: {len(clip_lengths)}\")\n",
    "\n",
    "    # Load other data if available\n",
    "    xpos_all = f[\"xpos\"][:] if \"xpos\" in f else None\n",
    "    xquat_all = f[\"xquat\"][:] if \"xquat\" in f else None\n",
    "    offsets = f[\"offsets\"][:] if \"offsets\" in f else None\n",
    "\n",
    "    # Load names\n",
    "    joint_names = (\n",
    "        [n.decode(\"utf-8\") for n in f[\"joint_names\"][:]] if \"joint_names\" in f else None\n",
    "    )\n",
    "    kp_names = (\n",
    "        [n.decode(\"utf-8\") for n in f[\"kp_names\"][:]] if \"kp_names\" in f else None\n",
    "    )\n",
    "\n",
    "print(f\"\\nTotal frames: {qpos_all.shape[0]}\")\n",
    "print(f\"qpos dimensions: {qpos_all.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape qpos into clips based on clip_lengths\n",
    "qpos_clips = []\n",
    "start_idx = 0\n",
    "\n",
    "for clip_len in clip_lengths:\n",
    "    end_idx = start_idx + clip_len\n",
    "    qpos_clips.append(qpos_all[start_idx:end_idx])\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(f\"Split into {len(qpos_clips)} clips\")\n",
    "print(f\"Clip length range: {min(clip_lengths)} - {max(clip_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load FicTrac Trajectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original CSV to get FicTrac data\n",
    "print(f\"Loading FicTrac data from {CSV_DATA_PATH}...\")\n",
    "full_df = pd.read_csv(CSV_DATA_PATH)\n",
    "print(f\"Loaded dataframe with shape: {full_df.shape}\")\n",
    "\n",
    "# Check for FicTrac columns\n",
    "fictrac_cols = [col for col in full_df.columns if 'fictrac' in col.lower()]\n",
    "print(f\"\\nFound {len(fictrac_cols)} FicTrac columns:\")\n",
    "for col in fictrac_cols[:10]:\n",
    "    print(f\"  - {col}\")\n",
    "if len(fictrac_cols) > 10:\n",
    "    print(f\"  ... and {len(fictrac_cols) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract walking bouts and FicTrac trajectory data\n",
    "all_bout_nums = full_df[\"walking_bout_number\"].unique()\n",
    "all_bout_nums = all_bout_nums[all_bout_nums > 0]  # Skip bout 0\n",
    "all_bout_nums = sorted(all_bout_nums)\n",
    "\n",
    "print(f\"Found {len(all_bout_nums)} walking bouts\")\n",
    "\n",
    "# Extract trajectory data for each bout\n",
    "int_x_cm = []  # Integrated X position in cm\n",
    "int_y_cm = []  # Integrated Y position in cm\n",
    "heading_deg = []  # Heading angle\n",
    "bout_clip_lengths = []  # Actual bout lengths from CSV\n",
    "\n",
    "for bout_num in tqdm(all_bout_nums, desc=\"Extracting FicTrac data\"):\n",
    "    bout = full_df[full_df[\"walking_bout_number\"] == bout_num]\n",
    "    bout_clip_lengths.append(len(bout))\n",
    "    \n",
    "    # Extract integrated position (convert mm to cm, swap axes for body model)\n",
    "    # Note: Axes are swapped because the model coordinate system differs from FicTrac\n",
    "    x_mm = bout[\"fictrac_int_y_mm\"].values  # Swapped\n",
    "    y_mm = bout[\"fictrac_int_x_mm\"].values  # Swapped\n",
    "    \n",
    "    # Convert to cm and subtract initial position\n",
    "    int_x_cm.append((x_mm / 10) - (x_mm[0] / 10))\n",
    "    int_y_cm.append((y_mm / 10) - (y_mm[0] / 10))\n",
    "    \n",
    "    # Extract heading (subtract initial to get relative heading)\n",
    "    heading = bout[\"fictrac_heading\"].values\n",
    "    heading_deg.append(heading - heading[0])\n",
    "\n",
    "print(f\"\\nExtracted {len(int_x_cm)} trajectory clips\")\n",
    "print(f\"Bout length range: {min(bout_clip_lengths)} - {max(bout_clip_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify clip counts match\n",
    "print(f\"STAC IK clips: {len(qpos_clips)}\")\n",
    "print(f\"FicTrac clips: {len(int_x_cm)}\")\n",
    "\n",
    "if len(qpos_clips) != len(int_x_cm):\n",
    "    print(f\"WARNING: Clip count mismatch!\")\n",
    "    # Use minimum\n",
    "    n_clips = min(len(qpos_clips), len(int_x_cm))\n",
    "    print(f\"Using first {n_clips} clips\")\n",
    "else:\n",
    "    n_clips = len(qpos_clips)\n",
    "    print(\"Clip counts match!\")\n",
    "\n",
    "# Verify lengths match for each clip\n",
    "length_mismatches = []\n",
    "for i in range(n_clips):\n",
    "    qpos_len = len(qpos_clips[i])\n",
    "    traj_len = len(int_x_cm[i])\n",
    "    if qpos_len != traj_len:\n",
    "        length_mismatches.append((i, qpos_len, traj_len))\n",
    "\n",
    "if length_mismatches:\n",
    "    print(f\"\\nFound {len(length_mismatches)} clips with length mismatches:\")\n",
    "    for i, qlen, tlen in length_mismatches[:5]:\n",
    "        print(f\"  Clip {i}: qpos={qlen}, traj={tlen}\")\n",
    "else:\n",
    "    print(\"All clip lengths match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quaternion Utilities\n",
    "\n",
    "Functions for quaternion operations (rotation, multiplication) needed for yaw integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_rot_axis(axis, angle):\n",
    "    \"\"\"\n",
    "    Create a quaternion representing rotation around an axis.\n",
    "    \n",
    "    Args:\n",
    "        axis: (3,) rotation axis (should be normalized)\n",
    "        angle: rotation angle in radians\n",
    "        \n",
    "    Returns:\n",
    "        q: (4,) quaternion [w, x, y, z]\n",
    "    \"\"\"\n",
    "    axis = axis / jnp.linalg.norm(axis)\n",
    "    half_angle = angle / 2.0\n",
    "    w = jnp.cos(half_angle)\n",
    "    xyz = axis * jnp.sin(half_angle)\n",
    "    return jnp.array([w, xyz[0], xyz[1], xyz[2]])\n",
    "\n",
    "\n",
    "def quat_mul(q1, q2):\n",
    "    \"\"\"\n",
    "    Multiply two quaternions.\n",
    "    \n",
    "    Args:\n",
    "        q1: (4,) first quaternion [w, x, y, z]\n",
    "        q2: (4,) second quaternion [w, x, y, z]\n",
    "        \n",
    "    Returns:\n",
    "        q: (4,) result quaternion\n",
    "    \"\"\"\n",
    "    w1, x1, y1, z1 = q1\n",
    "    w2, x2, y2, z2 = q2\n",
    "    \n",
    "    w = w1*w2 - x1*x2 - y1*y2 - z1*z2\n",
    "    x = w1*x2 + x1*w2 + y1*z2 - z1*y2\n",
    "    y = w1*y2 - x1*z2 + y1*w2 + z1*x2\n",
    "    z = w1*z2 + x1*y2 - y1*x2 + z1*w2\n",
    "    \n",
    "    return jnp.array([w, x, y, z])\n",
    "\n",
    "\n",
    "def normalize_quat(q):\n",
    "    \"\"\"\n",
    "    Normalize a quaternion to unit length.\n",
    "    \"\"\"\n",
    "    return q / jnp.linalg.norm(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trajectory Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yaw_from_trajectory(int_x, int_y, smoothing_window=75):\n",
    "    \"\"\"\n",
    "    Calculate smoothed yaw angles from trajectory position data.\n",
    "    \n",
    "    The yaw angle is computed from the direction of travel (velocity),\n",
    "    then smoothed with a Gaussian kernel for natural transitions.\n",
    "    \n",
    "    Args:\n",
    "        int_x: (T,) X position trajectory\n",
    "        int_y: (T,) Y position trajectory\n",
    "        smoothing_window: window size for Gaussian smoothing\n",
    "        \n",
    "    Returns:\n",
    "        yaw_angles: (T,) smoothed yaw angles in radians\n",
    "    \"\"\"\n",
    "    N = smoothing_window\n",
    "    original_length = int_x.shape[0]\n",
    "    \n",
    "    # Calculate velocity using smoothed finite differences\n",
    "    vel_window = 5\n",
    "    pad_x = jnp.pad(int_x, vel_window // 2, mode=\"edge\")\n",
    "    pad_y = jnp.pad(int_y, vel_window // 2, mode=\"edge\")\n",
    "    \n",
    "    # Smooth velocity calculation\n",
    "    vel_x = jnp.convolve(jnp.diff(pad_x), jnp.ones(vel_window) / vel_window, mode=\"valid\")\n",
    "    vel_y = jnp.convolve(jnp.diff(pad_y), jnp.ones(vel_window) / vel_window, mode=\"valid\")\n",
    "    \n",
    "    # Pad velocity to match original length\n",
    "    current_length = vel_x.shape[0]\n",
    "    pad_size = original_length - current_length\n",
    "    pad_left = pad_size // 2\n",
    "    pad_right = pad_size - pad_left\n",
    "    vel_x = jnp.pad(vel_x, (pad_left, pad_right), mode=\"edge\")\n",
    "    vel_y = jnp.pad(vel_y, (pad_left, pad_right), mode=\"edge\")\n",
    "    \n",
    "    # Calculate yaw from velocity direction\n",
    "    dyaw_t = jnp.arctan2(vel_y, vel_x)\n",
    "    \n",
    "    # Unwrap to handle angle discontinuities\n",
    "    unwrapped_yaw = jnp.unwrap(dyaw_t)\n",
    "    \n",
    "    # Gaussian smoothing kernel\n",
    "    sigma = N / 6.0\n",
    "    kernel_size = N + 1\n",
    "    x = jnp.arange(-N // 2, N // 2 + 1)\n",
    "    gaussian_kernel = jnp.exp(-0.5 * (x / sigma) ** 2)\n",
    "    gaussian_kernel = gaussian_kernel / jnp.sum(gaussian_kernel)\n",
    "    \n",
    "    # Apply Gaussian smoothing\n",
    "    pad_width = kernel_size // 2\n",
    "    padded_yaw = jnp.pad(unwrapped_yaw, pad_width, mode=\"edge\")\n",
    "    smooth_yaw_conv = jnp.convolve(padded_yaw, gaussian_kernel, mode=\"valid\")\n",
    "    \n",
    "    # Trim to original length\n",
    "    diff = smooth_yaw_conv.shape[0] - original_length\n",
    "    start = diff // 2\n",
    "    smooth_yaw = jax.lax.dynamic_slice(smooth_yaw_conv, (start,), (original_length,))\n",
    "    \n",
    "    return smooth_yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_clip_trajectory(\n",
    "    int_x_clip,\n",
    "    int_y_clip,\n",
    "    qpos_clip,\n",
    "    wing_joint_idxs,\n",
    "    default_wing_pos,\n",
    "    smoothing_window=75,\n",
    "    z_offset=0.0195,\n",
    "):\n",
    "    \"\"\"\n",
    "    Integrate trajectory data into a clip's qpos.\n",
    "    \n",
    "    Updates:\n",
    "    - X, Y positions from FicTrac integrated trajectory\n",
    "    - Z position adjusted by offset\n",
    "    - Quaternion orientation updated with calculated yaw\n",
    "    - Wing joints set to default (folded) position\n",
    "    \n",
    "    Args:\n",
    "        int_x_clip: (T,) X trajectory positions in cm\n",
    "        int_y_clip: (T,) Y trajectory positions in cm\n",
    "        qpos_clip: (T, nq) joint positions from STAC\n",
    "        wing_joint_idxs: indices of wing joints in qpos\n",
    "        default_wing_pos: default wing joint positions\n",
    "        smoothing_window: window for yaw smoothing\n",
    "        z_offset: height offset for z position\n",
    "        \n",
    "    Returns:\n",
    "        updated_qpos: (T, nq) qpos with integrated trajectory\n",
    "    \"\"\"\n",
    "    # Calculate smoothed yaw from trajectory\n",
    "    smooth_yaw = calculate_yaw_from_trajectory(int_x_clip, int_y_clip, smoothing_window)\n",
    "    \n",
    "    # Get initial quaternions from STAC output\n",
    "    # qpos format: [x, y, z, qw, qx, qy, qz, joint1, joint2, ...]\n",
    "    initial_quaternion = qpos_clip[:, 3:7]\n",
    "    \n",
    "    # Create yaw rotation quaternions (rotation around Z-axis)\n",
    "    z_axis = jnp.array([0.0, 0.0, 1.0])\n",
    "    yaw_quaternions = vmap(lambda angle: quat_rot_axis(z_axis, angle))(smooth_yaw)\n",
    "    \n",
    "    # Apply yaw rotation to initial orientation\n",
    "    final_quaternions = vmap(quat_mul)(yaw_quaternions, initial_quaternion)\n",
    "    \n",
    "    # Normalize quaternions\n",
    "    final_quaternions = vmap(normalize_quat)(final_quaternions)\n",
    "    \n",
    "    # Update qpos with trajectory data\n",
    "    updated_qpos = qpos_clip.at[:, 0].set(int_x_clip)  # X position\n",
    "    updated_qpos = updated_qpos.at[:, 1].set(int_y_clip)  # Y position\n",
    "    updated_qpos = updated_qpos.at[:, 2].set(jnp.min(qpos_clip[:, 2]) - z_offset)  # Z position\n",
    "    updated_qpos = updated_qpos.at[:, 3:7].set(final_quaternions)  # Quaternion\n",
    "    \n",
    "    # Set wing joints to default position\n",
    "    if wing_joint_idxs is not None and len(wing_joint_idxs) > 0:\n",
    "        for i, idx in enumerate(wing_joint_idxs):\n",
    "            if i < len(default_wing_pos):\n",
    "                updated_qpos = updated_qpos.at[:, idx].set(default_wing_pos[i])\n",
    "    \n",
    "    return updated_qpos\n",
    "\n",
    "\n",
    "# JIT compile\n",
    "jit_process_clip = jit(process_single_clip_trajectory, static_argnames=[\"smoothing_window\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get Wing Joint Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to find wing joint indices\n",
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "spec = mujoco.MjSpec().from_file(str(MODEL_PATH))\n",
    "mj_model = spec.compile()\n",
    "\n",
    "# Find wing joints\n",
    "wing_joint_names = [joint.name for joint in spec.joints if 'wing' in joint.name.lower()]\n",
    "print(f\"Wing joints: {wing_joint_names}\")\n",
    "\n",
    "# Get joint indices in qpos\n",
    "# Note: qpos includes root position (3) + quaternion (4) + joint angles\n",
    "# So joint indices start at 7\n",
    "all_joint_names = [joint.name for joint in spec.joints]\n",
    "wing_joint_idxs = []\n",
    "\n",
    "for wing_name in wing_joint_names:\n",
    "    if wing_name in all_joint_names:\n",
    "        # Find the index in joint list (excluding free joint if any)\n",
    "        joint_idx = all_joint_names.index(wing_name)\n",
    "        # Add offset for root position and quaternion\n",
    "        qpos_idx = 7 + joint_idx  # 3 pos + 4 quat + joint index\n",
    "        wing_joint_idxs.append(qpos_idx)\n",
    "        print(f\"  {wing_name}: joint_idx={joint_idx}, qpos_idx={qpos_idx}\")\n",
    "\n",
    "wing_joint_idxs = tuple(wing_joint_idxs) if wing_joint_idxs else None\n",
    "print(f\"\\nWing joint qpos indices: {wing_joint_idxs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Sample Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample trajectory before processing\n",
    "sample_idx = 19  # Change this to view different clips\n",
    "\n",
    "if sample_idx < len(int_x_cm):\n",
    "    x = int_x_cm[sample_idx]\n",
    "    y = int_y_cm[sample_idx]\n",
    "    \n",
    "    # Calculate yaw for visualization\n",
    "    test_yaw = np.array(calculate_yaw_from_trajectory(jnp.array(x), jnp.array(y), SMOOTHING_WINDOW))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot trajectory with yaw directions\n",
    "    u = np.cos(test_yaw)\n",
    "    v = np.sin(test_yaw)\n",
    "    \n",
    "    axes[0].plot(x, y, 'k-', linewidth=2, label='Trajectory')\n",
    "    axes[0].scatter(x[0], y[0], c='g', s=100, label='Start', zorder=5)\n",
    "    axes[0].scatter(x[-1], y[-1], c='r', s=100, label='End', zorder=5)\n",
    "    \n",
    "    # Plot yaw direction arrows (every 10 frames)\n",
    "    step = max(1, len(x) // 20)\n",
    "    axes[0].quiver(x[::step], y[::step], u[::step], v[::step],\n",
    "                   angles='xy', scale_units='xy', scale=10, color='b', alpha=0.7)\n",
    "    \n",
    "    axes[0].set_xlabel('X (cm)')\n",
    "    axes[0].set_ylabel('Y (cm)')\n",
    "    axes[0].set_title(f'Clip {sample_idx}: COM Trajectory with Yaw Direction')\n",
    "    axes[0].axis('equal')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot yaw over time\n",
    "    axes[1].plot(test_yaw, 'b-', linewidth=2)\n",
    "    axes[1].set_xlabel('Frame')\n",
    "    axes[1].set_ylabel('Yaw Angle (radians)')\n",
    "    axes[1].set_title('Yaw Angle Evolution')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Sample index {sample_idx} out of range (max: {len(int_x_cm)-1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Process All Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all clips with trajectory integration\n",
    "print(f\"Processing {n_clips} clips with trajectory integration...\")\n",
    "\n",
    "processed_qpos = []\n",
    "\n",
    "for clip_idx in tqdm(range(n_clips), desc=\"Integrating trajectories\"):\n",
    "    # Get data for this clip\n",
    "    int_x = jnp.array(int_x_cm[clip_idx])\n",
    "    int_y = jnp.array(int_y_cm[clip_idx])\n",
    "    qpos = jnp.array(qpos_clips[clip_idx])\n",
    "    \n",
    "    # Handle length mismatch by truncating to minimum\n",
    "    min_len = min(len(int_x), len(qpos))\n",
    "    int_x = int_x[:min_len]\n",
    "    int_y = int_y[:min_len]\n",
    "    qpos = qpos[:min_len]\n",
    "    \n",
    "    # Process this clip\n",
    "    updated_qpos = jit_process_clip(\n",
    "        int_x,\n",
    "        int_y,\n",
    "        qpos,\n",
    "        wing_joint_idxs,\n",
    "        DEFAULT_WING_POS,\n",
    "        smoothing_window=SMOOTHING_WINDOW,\n",
    "        z_offset=Z_OFFSET,\n",
    "    )\n",
    "    \n",
    "    processed_qpos.append(np.array(updated_qpos))\n",
    "\n",
    "print(f\"\\nProcessed {len(processed_qpos)} clips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optional: Interpolate to Higher Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_clip(clip_data, source_hz, target_hz):\n",
    "    \"\"\"\n",
    "    Interpolate a clip to a different frequency using cubic splines.\n",
    "    \n",
    "    Args:\n",
    "        clip_data: (T, D) array\n",
    "        source_hz: source frequency\n",
    "        target_hz: target frequency\n",
    "        \n",
    "    Returns:\n",
    "        interpolated: (T_new, D) array\n",
    "    \"\"\"\n",
    "    T, D = clip_data.shape\n",
    "    duration = T / source_hz\n",
    "    \n",
    "    t_source = np.linspace(0, duration, T)\n",
    "    T_new = int(duration * target_hz)\n",
    "    t_target = np.linspace(0, duration, T_new)\n",
    "    \n",
    "    interpolated = np.zeros((T_new, D))\n",
    "    for d in range(D):\n",
    "        spline = interpolate.CubicSpline(t_source, clip_data[:, d])\n",
    "        interpolated[:, d] = spline(t_target)\n",
    "    \n",
    "    # Re-normalize quaternions (indices 3:7)\n",
    "    quat = interpolated[:, 3:7]\n",
    "    quat_norm = np.linalg.norm(quat, axis=1, keepdims=True)\n",
    "    interpolated[:, 3:7] = quat / quat_norm\n",
    "    \n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TARGET_HZ is not None and TARGET_HZ != SOURCE_HZ:\n",
    "    print(f\"Interpolating from {SOURCE_HZ}Hz to {TARGET_HZ}Hz...\")\n",
    "    \n",
    "    interpolated_qpos = []\n",
    "    new_clip_lengths = []\n",
    "    \n",
    "    for clip_idx, clip in enumerate(tqdm(processed_qpos, desc=\"Interpolating\")):\n",
    "        interp_clip = interpolate_clip(clip, SOURCE_HZ, TARGET_HZ)\n",
    "        interpolated_qpos.append(interp_clip)\n",
    "        new_clip_lengths.append(len(interp_clip))\n",
    "    \n",
    "    final_qpos = interpolated_qpos\n",
    "    final_clip_lengths = new_clip_lengths\n",
    "    output_hz = TARGET_HZ\n",
    "    \n",
    "    print(f\"Interpolation complete!\")\n",
    "    print(f\"Original total frames: {sum(len(c) for c in processed_qpos)}\")\n",
    "    print(f\"Interpolated total frames: {sum(final_clip_lengths)}\")\n",
    "else:\n",
    "    print(f\"No interpolation (source={SOURCE_HZ}Hz, target={TARGET_HZ}Hz)\")\n",
    "    final_qpos = processed_qpos\n",
    "    final_clip_lengths = [len(c) for c in processed_qpos]\n",
    "    output_hz = SOURCE_HZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before and after trajectory integration\n",
    "sample_idx = 19\n",
    "\n",
    "if sample_idx < len(qpos_clips) and sample_idx < len(final_qpos):\n",
    "    original = qpos_clips[sample_idx]\n",
    "    processed = final_qpos[sample_idx]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # X position\n",
    "    axes[0, 0].plot(original[:, 0], 'b-', label='Original', alpha=0.7)\n",
    "    # Resample processed to match original length for comparison if interpolated\n",
    "    if len(processed) != len(original):\n",
    "        t_orig = np.arange(len(original))\n",
    "        t_proc = np.linspace(0, len(original)-1, len(processed))\n",
    "        axes[0, 0].plot(t_proc, processed[:, 0], 'r-', label='With Trajectory', alpha=0.7)\n",
    "    else:\n",
    "        axes[0, 0].plot(processed[:, 0], 'r-', label='With Trajectory', alpha=0.7)\n",
    "    axes[0, 0].set_ylabel('X Position (cm)')\n",
    "    axes[0, 0].set_title('X Position')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Y position\n",
    "    axes[0, 1].plot(original[:, 1], 'b-', label='Original', alpha=0.7)\n",
    "    if len(processed) != len(original):\n",
    "        axes[0, 1].plot(t_proc, processed[:, 1], 'r-', label='With Trajectory', alpha=0.7)\n",
    "    else:\n",
    "        axes[0, 1].plot(processed[:, 1], 'r-', label='With Trajectory', alpha=0.7)\n",
    "    axes[0, 1].set_ylabel('Y Position (cm)')\n",
    "    axes[0, 1].set_title('Y Position')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # XY trajectory\n",
    "    axes[1, 0].plot(original[:, 0], original[:, 1], 'b-', label='Original', alpha=0.7)\n",
    "    axes[1, 0].plot(processed[:, 0], processed[:, 1], 'r-', label='With Trajectory', alpha=0.7)\n",
    "    axes[1, 0].scatter(processed[0, 0], processed[0, 1], c='g', s=100, zorder=5, label='Start')\n",
    "    axes[1, 0].set_xlabel('X (cm)')\n",
    "    axes[1, 0].set_ylabel('Y (cm)')\n",
    "    axes[1, 0].set_title('XY Trajectory')\n",
    "    axes[1, 0].axis('equal')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Quaternion W component (shows orientation changes)\n",
    "    axes[1, 1].plot(original[:, 3], 'b-', label='Original qw', alpha=0.7)\n",
    "    if len(processed) != len(original):\n",
    "        axes[1, 1].plot(t_proc, processed[:, 3], 'r-', label='With Trajectory qw', alpha=0.7)\n",
    "    else:\n",
    "        axes[1, 1].plot(processed[:, 3], 'r-', label='With Trajectory qw', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Frame')\n",
    "    axes[1, 1].set_ylabel('Quaternion W')\n",
    "    axes[1, 1].set_title('Orientation (Quaternion W)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Sample index {sample_idx} out of range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all clips\n",
    "qpos_final = np.concatenate(final_qpos, axis=0)\n",
    "print(f\"Final qpos shape: {qpos_final.shape}\")\n",
    "print(f\"Total frames: {qpos_final.shape[0]}\")\n",
    "print(f\"Output frequency: {output_hz}Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final trajectory-integrated data\n",
    "print(f\"Saving to {OUTPUT_PATH}...\")\n",
    "\n",
    "with h5py.File(OUTPUT_PATH, 'w') as f:\n",
    "    # Metadata\n",
    "    f.attrs['description'] = 'Trajectory-integrated walking data with FicTrac motion'\n",
    "    f.attrs['source_stac_ik'] = str(STAC_IK_PATH)\n",
    "    f.attrs['source_csv'] = str(CSV_DATA_PATH)\n",
    "    f.attrs['output_hz'] = output_hz\n",
    "    f.attrs['source_hz'] = SOURCE_HZ\n",
    "    f.attrs['smoothing_window'] = SMOOTHING_WINDOW\n",
    "    f.attrs['z_offset'] = Z_OFFSET\n",
    "    f.attrs['n_clips'] = len(final_qpos)\n",
    "    f.attrs['n_frames'] = qpos_final.shape[0]\n",
    "    \n",
    "    # Main data\n",
    "    f.create_dataset('qpos', data=qpos_final, compression='gzip')\n",
    "    f.create_dataset('clip_lengths', data=np.array(final_clip_lengths))\n",
    "    \n",
    "    # Also save individual clips for convenience\n",
    "    clips_grp = f.create_group('clips')\n",
    "    for i, clip in enumerate(final_qpos):\n",
    "        clips_grp.create_dataset(f'clip_{i:04d}', data=clip, compression='gzip')\n",
    "    \n",
    "    # Copy over other relevant data from STAC output\n",
    "    if offsets is not None:\n",
    "        f.create_dataset('offsets', data=offsets, compression='gzip')\n",
    "    if joint_names is not None:\n",
    "        f.create_dataset('joint_names', data=np.array(joint_names, dtype='S'))\n",
    "    if kp_names is not None:\n",
    "        f.create_dataset('kp_names', data=np.array(kp_names, dtype='S'))\n",
    "\n",
    "print(f\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved file\n",
    "print(\"\\nVerifying saved file...\")\n",
    "with h5py.File(OUTPUT_PATH, 'r') as f:\n",
    "    print(f\"Attributes: {dict(f.attrs)}\")\n",
    "    print(f\"\\nDatasets:\")\n",
    "    for key in f.keys():\n",
    "        if isinstance(f[key], h5py.Dataset):\n",
    "            print(f\"  {key}: {f[key].shape}\")\n",
    "        elif isinstance(f[key], h5py.Group):\n",
    "            print(f\"  {key}/: {len(f[key])} items\")\n",
    "\n",
    "print(f\"\\nOutput file: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Loaded STAC IK output (joint angles) from Notebook 2\n",
    "2. Loaded FicTrac trajectory data (wheel rotation/displacement) from the original CSV\n",
    "3. Calculated yaw orientation from the trajectory direction of travel\n",
    "4. Applied trajectory position (X, Y) and orientation (yaw) to update qpos\n",
    "5. Set wing joints to default folded position\n",
    "6. Optionally interpolated to higher frequency\n",
    "7. Exported trajectory-integrated data to H5\n",
    "\n",
    "**Output:** `walking_trajectory_integrated.h5` containing:\n",
    "- `qpos`: Joint positions with integrated trajectory motion\n",
    "- `clip_lengths`: Length of each walking bout clip\n",
    "- `clips/`: Individual clips for convenience\n",
    "\n",
    "The data is now ready for use in simulation, imitation learning, or biomechanical analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic-mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
